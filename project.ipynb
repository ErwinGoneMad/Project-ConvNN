{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration, Analyse, Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./kaggle/working/ships32\"\n",
    "batch_size = 64\n",
    "img_size = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory,\n",
    "    image_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    seed=42,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory,\n",
    "    image_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    seed=42,\n",
    "    subset=\"validation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {}\n",
    "for image, label in train_ds.unbatch():\n",
    "    label_val = label.numpy()  # Get the actual label value\n",
    "    if label_val in class_counts:\n",
    "        class_counts[label_val] += 1\n",
    "    else:\n",
    "        class_counts[label_val] = 1\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "classes = list(class_counts.keys())\n",
    "counts = list(class_counts.values())\n",
    "plt.bar(classes, counts)\n",
    "plt.xlabel(\"Boat Class\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution in Training Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoatNet_30(input_shape=(32, 32, 3), num_classes=13):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # First block\n",
    "    skip1 = x\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.add([x, skip1])\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Second block\n",
    "    x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    skip2 = x\n",
    "    x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.add([x, skip2])\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Final features\n",
    "    x = layers.Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Classification head\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoatNet_30()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "print(\"Nombre de couches : \", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultat à soumettre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./kaggle/input/navires-2025/ships_competition.npz\", allow_pickle=True)[\n",
    "    \"X\"\n",
    "]\n",
    "X_test = X_test.astype(\"float32\") / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test).argmax(axis=1)\n",
    "df = pd.DataFrame({\"Category\": res})\n",
    "df.to_csv(\"reco_nav.csv\", index_label=\"Id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head reco_nav.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"./kaggle/working\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(r\"reco_nav.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11655307,
     "sourceId": 97843,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
